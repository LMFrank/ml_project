{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 90,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "n_samples = 100000\n",
    "user_ids = np.random.randint(1, 10001, size=n_samples)\n",
    "movie_ids = np.random.randint(1, 1001, size=n_samples)\n",
    "ratings = np.random.randint(1, 6, size=n_samples)\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'UserID': user_ids,\n",
    "    'MovieID': movie_ids,\n",
    "    'Rating': ratings\n",
    "})\n",
    "\n",
    "df.to_csv('data.csv', index=False, header=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\njuxu\\AppData\\Local\\Temp\\ipykernel_25320\\1895937647.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X['UserID'] = le_u.fit_transform(X['UserID'])\n",
      "C:\\Users\\njuxu\\AppData\\Local\\Temp\\ipykernel_25320\\1895937647.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X['MovieID'] = le_m.fit_transform(X['MovieID'])\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "\n",
    "df = pd.read_csv('data.csv')\n",
    "X = df[['UserID', 'MovieID']]\n",
    "y = df['Rating']\n",
    "\n",
    "# UserID和MovieID进行编码\n",
    "le_u = LabelEncoder()\n",
    "le_m = LabelEncoder()\n",
    "X['UserID'] = le_u.fit_transform(X['UserID'])\n",
    "X['MovieID'] = le_m.fit_transform(X['MovieID'])\n",
    "\n",
    "# 划分训练集和测试集\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_train = X_train.astype('float32')\n",
    "y_train = y_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "y_test = y_test.astype('float32')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class Recommender(nn.Module):\n",
    "    def __init__(self, num_users, num_movies, embedding_size, hidden_size):\n",
    "        super().__init__()\n",
    "        self.user_embedding = nn.Embedding(num_users, embedding_size)\n",
    "        self.movie_embedding = nn.Embedding(num_movies, embedding_size)\n",
    "        self.fc = nn.Linear(embedding_size * 2, hidden_size)\n",
    "        self.output = nn.Linear(hidden_size, 1)\n",
    "\n",
    "    def forward(self, user_ids, movie_ids):\n",
    "        user_emb = self.user_embedding(user_ids)\n",
    "        movie_emb = self.movie_embedding(movie_ids)\n",
    "        x = torch.cat([user_emb, movie_emb], dim=1)\n",
    "        x = self.fc(x)\n",
    "        x = nn.ReLU()(x)\n",
    "        x = self.output(x)\n",
    "        return x"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "model = Recommender(num_users=len(le_u.classes_), num_movies=len(le_m.classes_), embedding_size=32, hidden_size=64)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 625/625 [00:02<00:00, 210.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 2.7117916975021363\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 625/625 [00:03<00:00, 181.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Loss: 2.039401442337036\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 625/625 [00:03<00:00, 178.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Loss: 1.9783723110198974\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 625/625 [00:03<00:00, 198.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Loss: 1.9296103435516356\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 625/625 [00:03<00:00, 190.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, Loss: 1.8833528064727783\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|██████████| 625/625 [00:03<00:00, 205.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6, Loss: 1.8338251295089723\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|██████████| 625/625 [00:02<00:00, 224.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7, Loss: 1.7792311292648315\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|██████████| 625/625 [00:02<00:00, 222.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, Loss: 1.7197045665740966\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 625/625 [00:02<00:00, 226.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9, Loss: 1.653863657951355\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10: 100%|██████████| 625/625 [00:02<00:00, 225.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, Loss: 1.5859351306915284\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "batch_size = 128\n",
    "train_dataset = TensorDataset(torch.tensor(X_train.values), torch.tensor(y_train.values))\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    running_loss = 0.0\n",
    "    for i, (inputs, labels) in enumerate(tqdm(train_dataloader, desc=f'Epoch {epoch+1}')):\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs[:, 0].long(), inputs[:, 1].long())\n",
    "        loss = criterion(outputs.squeeze(), labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    print(f'Epoch {epoch+1}, Loss: {running_loss / len(train_dataloader)}')\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:00<00:00, 813.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 2.3194596129617873\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "test_dataset = TensorDataset(torch.tensor(X_test.values), torch.tensor(y_test.values))\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size)\n",
    "with torch.no_grad():\n",
    "    running_loss = 0.0\n",
    "    for inputs, labels in tqdm(test_dataloader):\n",
    "        outputs = model(inputs[:, 0].long(), inputs[:, 1].long())\n",
    "        loss = criterion(outputs.squeeze(), labels)\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    print(f'Test Loss: {running_loss / len(test_dataloader)}')\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Input \u001B[1;32mIn [108]\u001B[0m, in \u001B[0;36m<cell line: 8>\u001B[1;34m()\u001B[0m\n\u001B[0;32m      6\u001B[0m user_ids \u001B[38;5;241m=\u001B[39m X_test[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mUserID\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;241m.\u001B[39munique()\n\u001B[0;32m      7\u001B[0m movie_ids \u001B[38;5;241m=\u001B[39m X_test[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mMovieID\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;241m.\u001B[39munique()\n\u001B[1;32m----> 8\u001B[0m random_user_ids \u001B[38;5;241m=\u001B[39m \u001B[43mrandom\u001B[49m\u001B[38;5;241m.\u001B[39msample(\u001B[38;5;28mlist\u001B[39m(user_ids), \u001B[38;5;241m5\u001B[39m)\n\u001B[0;32m      9\u001B[0m random_movie_ids \u001B[38;5;241m=\u001B[39m random\u001B[38;5;241m.\u001B[39msample(\u001B[38;5;28mlist\u001B[39m(movie_ids), \u001B[38;5;241m5\u001B[39m)\n\u001B[0;32m     11\u001B[0m \u001B[38;5;66;03m# 构造输入数据\u001B[39;00m\n",
      "Input \u001B[1;32mIn [108]\u001B[0m, in \u001B[0;36m<cell line: 8>\u001B[1;34m()\u001B[0m\n\u001B[0;32m      6\u001B[0m user_ids \u001B[38;5;241m=\u001B[39m X_test[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mUserID\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;241m.\u001B[39munique()\n\u001B[0;32m      7\u001B[0m movie_ids \u001B[38;5;241m=\u001B[39m X_test[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mMovieID\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;241m.\u001B[39munique()\n\u001B[1;32m----> 8\u001B[0m random_user_ids \u001B[38;5;241m=\u001B[39m \u001B[43mrandom\u001B[49m\u001B[38;5;241m.\u001B[39msample(\u001B[38;5;28mlist\u001B[39m(user_ids), \u001B[38;5;241m5\u001B[39m)\n\u001B[0;32m      9\u001B[0m random_movie_ids \u001B[38;5;241m=\u001B[39m random\u001B[38;5;241m.\u001B[39msample(\u001B[38;5;28mlist\u001B[39m(movie_ids), \u001B[38;5;241m5\u001B[39m)\n\u001B[0;32m     11\u001B[0m \u001B[38;5;66;03m# 构造输入数据\u001B[39;00m\n",
      "File \u001B[1;32m_pydevd_bundle\\pydevd_cython_win32_39_64.pyx:1179\u001B[0m, in \u001B[0;36m_pydevd_bundle.pydevd_cython_win32_39_64.SafeCallWrapper.__call__\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32m_pydevd_bundle\\pydevd_cython_win32_39_64.pyx:620\u001B[0m, in \u001B[0;36m_pydevd_bundle.pydevd_cython_win32_39_64.PyDBFrame.trace_dispatch\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32m_pydevd_bundle\\pydevd_cython_win32_39_64.pyx:1095\u001B[0m, in \u001B[0;36m_pydevd_bundle.pydevd_cython_win32_39_64.PyDBFrame.trace_dispatch\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32m_pydevd_bundle\\pydevd_cython_win32_39_64.pyx:1053\u001B[0m, in \u001B[0;36m_pydevd_bundle.pydevd_cython_win32_39_64.PyDBFrame.trace_dispatch\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32mC:\\ProgramSoftware\\JetBrains\\PyCharm 2022.3.2\\plugins\\python\\helpers-pro\\jupyter_debug\\pydev_jupyter_plugin.py:169\u001B[0m, in \u001B[0;36mstop\u001B[1;34m(plugin, pydb, frame, event, args, stop_info, arg, step_cmd)\u001B[0m\n\u001B[0;32m    167\u001B[0m     frame \u001B[38;5;241m=\u001B[39m suspend_jupyter(main_debugger, thread, frame, step_cmd)\n\u001B[0;32m    168\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m frame:\n\u001B[1;32m--> 169\u001B[0m         \u001B[43mmain_debugger\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdo_wait_suspend\u001B[49m\u001B[43m(\u001B[49m\u001B[43mthread\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mframe\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mevent\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43marg\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    170\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[0;32m    171\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;01mFalse\u001B[39;00m\n",
      "File \u001B[1;32mC:\\ProgramSoftware\\JetBrains\\PyCharm 2022.3.2\\plugins\\python\\helpers\\pydev\\pydevd.py:1160\u001B[0m, in \u001B[0;36mPyDB.do_wait_suspend\u001B[1;34m(self, thread, frame, event, arg, send_suspend_message, is_unhandled_exception)\u001B[0m\n\u001B[0;32m   1157\u001B[0m         from_this_thread\u001B[38;5;241m.\u001B[39mappend(frame_id)\n\u001B[0;32m   1159\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_threads_suspended_single_notification\u001B[38;5;241m.\u001B[39mnotify_thread_suspended(thread_id, stop_reason):\n\u001B[1;32m-> 1160\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_do_wait_suspend\u001B[49m\u001B[43m(\u001B[49m\u001B[43mthread\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mframe\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mevent\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43marg\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msuspend_type\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfrom_this_thread\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mC:\\ProgramSoftware\\JetBrains\\PyCharm 2022.3.2\\plugins\\python\\helpers\\pydev\\pydevd.py:1175\u001B[0m, in \u001B[0;36mPyDB._do_wait_suspend\u001B[1;34m(self, thread, frame, event, arg, suspend_type, from_this_thread)\u001B[0m\n\u001B[0;32m   1172\u001B[0m             \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_mpl_hook()\n\u001B[0;32m   1174\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mprocess_internal_commands()\n\u001B[1;32m-> 1175\u001B[0m         \u001B[43mtime\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msleep\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m0.01\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1177\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcancel_async_evaluation(get_current_thread_id(thread), \u001B[38;5;28mstr\u001B[39m(\u001B[38;5;28mid\u001B[39m(frame)))\n\u001B[0;32m   1179\u001B[0m \u001B[38;5;66;03m# process any stepping instructions\u001B[39;00m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "import random\n",
    "import torch\n",
    "\n",
    "\n",
    "# 随机生成一些用户和电影\n",
    "user_ids = X_test['UserID'].unique()\n",
    "movie_ids = X_test['MovieID'].unique()\n",
    "random_user_ids = random.sample(list(user_ids), 5)\n",
    "random_movie_ids = random.sample(list(movie_ids), 5)\n",
    "\n",
    "# 构造输入数据\n",
    "random_user_ids = np.array(random_user_ids)\n",
    "random_movie_ids = np.array(random_movie_ids)\n",
    "\n",
    "# 将 random_user_ids 和 random_movie_ids 扩展为 5x5 的矩阵\n",
    "random_user_ids = np.repeat(random_user_ids.reshape(-1, 1), 5, axis=1)\n",
    "random_movie_ids = np.repeat(random_movie_ids.reshape(1, -1), 5, axis=0)\n",
    "\n",
    "# 生成输入数据\n",
    "inputs = torch.tensor(np.column_stack((\n",
    "    random_user_ids.ravel(),\n",
    "    random_movie_ids.ravel()\n",
    "))).long()\n",
    "\n",
    "# 预测评分\n",
    "preds = model(inputs[:, 0], inputs[:, 1]).detach().numpy().ravel()\n",
    "\n",
    "# 输出预测结果\n",
    "for i, user_id in enumerate(random_user_ids):\n",
    "    print(f'对于用户 {int(user_id[0])}，推荐电影评分如下：')\n",
    "    for j in range(5):\n",
    "        movie_id = movie_ids[i * 5 + j]\n",
    "        print(f'    电影 {movie_id} 的评分为 {preds[i*5+j]:.2f}')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
